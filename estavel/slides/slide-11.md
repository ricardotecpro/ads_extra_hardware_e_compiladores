<!-- .element: class="fragment" -->
# Aula 11 - Paralelismo no Hardware
## ApresentaÃ§Ã£o

---

O cÃ³digo Multithreading (visto na Aula 09 e 10) Ã© uma abstraÃ§Ã£o do Sistema Operacional. Mas como a fÃ­sica do processador de fato abraÃ§a mÃºltiplas frentes de execuÃ§Ã£o simÃ©trica simultÃ¢nea?

---

---

<!-- .element: class="fragment" -->
# Novo TÃ³pico
## ğŸ—ï¸ 1. Multi-Core (MÃºltiplos NÃºcleos)

---

## ğŸ—ï¸ 1. Multi-Core (MÃºltiplos NÃºcleos)

Diferente do passado, onde havia um Ãºnico nÃºcleo saltando entre aplicativos (Context Switch), hoje temos vÃ¡rios nÃºcleos fÃ­sicos no mesmo invÃ³lucro (Chip).

- **Core FÃ­sico:** Ã‰ uma CPU completa e independente, com sua prÃ³pria ALU, Unidade de Controle e Caches L1/L2 particulares.
- **Cache L3 Compartilhado:** Na maioria dos designs AMD e Intel reais, os MÃºltiplos Cores (Ex: 8 Cores) conversam e trocam estados atravÃ©s de uma suntuosa e lenta Ã¡rea comum L3 que circunda todos os processadores ali impressos no wafer.

---

## ğŸ—ï¸ 1. Multi-Core (MÃºltiplos NÃºcleos)

> [!TIP]
> **Em Backend pesado:** Se o banco mapear duas Threads puras `backend` em dois Cores puramente isolados (Ex: Core 0 e Core 1), e elas lerem/trabalharem na mesma matriz contÃ­nua, o Hardware forÃ§arÃ¡ intercÃ¢mbios elÃ©tricos no *Cache Coherence Protocol (MESI)* rodando por toda placa mÃ£e. Fiquem espertos com o *False Sharing*!

---

## ğŸ—ï¸ 1. Multi-Core (MÃºltiplos NÃºcleos)

---

---

<!-- .element: class="fragment" -->
# Novo TÃ³pico
## ğŸ§¬ 2. Hyper-Threading (SMT - Symmetrical Multi-Threading)

---

## ğŸ§¬ 2. Hyper-Threading (SMT - Symmetrical Multi-Threading)

A mÃ¡gica comercial da Intel e AMD nos anos 2000. Como fazer "1 Core FÃ­sico" fingir ser "2 Cores LÃ³gicos" para o Windows/Linux?

Na aula 03, vimos que a execuÃ§Ã£o cruza pelo Pipeline ou pode esbarrar em ciclos ociosos na CU aguardando a MemÃ³ria Principal. O *Hyper-Threading* espeta um **Segundo conjunto de Registradores** e Hardware de Estado no mesmo Core. Enquanto o cÃ³digo da Thread "A" estÃ¡ 0.5 nanosegundo *travada* esperando chegar o dado lento da L3, o Core troca instantaneamente para o contexto da Thread "B", executando-o usando as mesmas Unidades LÃ³gicas (ALU) num aproveitamento fabril monstruoso de 100%.

---

## ğŸ§¬ 2. Hyper-Threading (SMT - Symmetrical Multi-Threading)

<div class="termy" markdown="1">

__CODE_BLOCK_0__

</div>

---

## ğŸ§¬ 2. Hyper-Threading (SMT - Symmetrical Multi-Threading)

> Vemos 8 CPUs acima, mas fisicamente a mÃ¡quina tem 4 motores reais.

---

## ğŸ§¬ 2. Hyper-Threading (SMT - Symmetrical Multi-Threading)

---

---

<!-- .element: class="fragment" -->
# Novo TÃ³pico
## ğŸ® 3. GPUs: O Paralelismo MaciÃ§o

---

## ğŸ® 3. GPUs: O Paralelismo MaciÃ§o

CPUs (Processadores) foram feitos para "Serem RÃ¡pidos executando sequÃªncias lÃ³gicas e IFs complexos". Possuem Caches gigantes.
GPUs (Placas de VÃ­deo) foram feitas para "Executar a MESMÃSSIMA MINÃšSCULA matemÃ¡tica simultaneamente em milhares de pixels fracos". Sem grandes condicionais, focando no *Throughput*.

NVIDIA e CUDA (plataforma de C++) reinam supremas em *Deep Learning* e Criptografia exatamente porque pegam *Loops For* gigantescos de Ãlgebra Linear, e fracionam em **8.000 mini-nÃºcleos (CUDA cores)** esmagando qualquer Intel Core i9 na latÃªncia matemÃ¡tica contÃ­nua pura.

---

<!-- .element: class="fragment" -->
# Novo TÃ³pico
## ğŸš€ Resumo PrÃ¡tico

---

## ğŸš€ Resumo PrÃ¡tico

- **Task Paralelism**: <span class="fragment">Se tens lÃ³gica variada, use a *CPU Multi-Core C++ thread pool*.</span>
- **Data Paralelism**: <span class="fragment">Se a conta for a repetiÃ§Ã£o retumbante de um algoritmo idÃªntico sobre 2 milhÃµes de dados sem dependÃªncia de saltos complexos, mova-a da RAM Ã  VRAM da *GPU via CUDA/OpenCL*. A mÃ©trica vai das horas paras os dÃ©cimos de segundo.</span>

---

## ğŸš€ Resumo PrÃ¡tico

---